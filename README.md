# Evaluation Metrics

## Classification:
  Evaluation Metrics | Values
| -----------------| -------------|
 Accuracy          |0.9522  |
 Recall            |0.49    |
 F1-Score          |0.66    |

## Detection:
  Evaluation Metrics            | Values
| ------------------------------| -------------|
 Mean-Average Precision@0.5        |0.7203|
 Mean-Average Precision@0.5 - 0.95  |0.4886|
 Average Precision              |  0.7557  |
 Average Recall                 |0.6589|
 Intersection over Union(IoU)   |  0.4577  |


## 2.10 Best images selected from the validation dataset showing its classification and detection
![img- (460)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/4bc01a28-5b1d-4881-953a-0c7b5fbc7ae4)
![img- (207)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/e396f8a4-fa0d-4cf0-bee5-5c3f18f90223)
![img- (181)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/51c6d0ad-4a14-49da-8450-a515d8cfa73b)
![img- (157)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/10d6aeac-8cb0-46d6-95f8-04c198ab46dc)
![img- (155)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/49795fe9-a6b6-4ace-a97a-6b2a79f6af80)
![img- (154)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/27616227-48e9-44f0-86ea-e32a3c24ca8a)
![img- (131)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/a5198b39-7d88-452e-ba8f-1d86d6d0984a)
![img- (99)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/43cabaef-6bec-4594-9ba6-829e1a94a849)
![img- (59)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/43841a5b-542a-4ad1-9b50-f31c84fa169c)
![img- (44)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/d7484bb9-2041-4c1d-903e-849280a425a1)

## 3.Images of the achieved interpretability plot of 10 best images selected from the validation dataset.
![img- (1308)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/d50aaa4a-dd2f-4802-91c9-5a331da71452)
![img- (1256)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/af173df2-d3fc-4ba7-a352-1bb885a883ff)
![img- (1252)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/929f5196-ce2e-42b7-b9a6-5b39f1a3d53b)
![img- (1243)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/ab409b73-ce4d-4574-befa-af3fbebcb115)
![img- (1239)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/55ae72d0-3cd6-4572-bc20-dc68dff702c2)
![img- (161)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/0ade2644-ea5e-4b00-aeb7-86756614bc60)
![img- (158)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/359f9181-ff0a-4234-ba7b-5a35c4cf395c)
![img- (157)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/53d8531e-d71b-4af4-a870-fecbd9a34b53)
![img- (155)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/77bcc1f2-26dd-40eb-85fd-bba089520154)
![img- (147)](https://github.com/anirudhprdhan/MISA-HUB-Auto-WCEBleedGen-Challenge/assets/61653573/fc42e163-31ed-412a-9206-2f95cacf0dd2)


 ## 4.Images of any 5 best images selected from testing datasets 1
 ![A0047](https://github.com/anirudhprdhan/new/assets/61653573/f8d7d9da-f0fa-4619-a855-78a30ebc7e80)
![A0046](https://github.com/anirudhprdhan/new/assets/61653573/e969daac-8bd6-4e64-a9e7-04d7669eeda1)
![A0041](https://github.com/anirudhprdhan/new/assets/61653573/787de155-517e-49b4-b730-99cc1a774535)
![A0007](https://github.com/anirudhprdhan/new/assets/61653573/84f0438d-7b74-43a3-97b6-0b7fc23f7c7a)
![A0000](https://github.com/anirudhprdhan/new/assets/61653573/084cf778-716d-409c-91c6-02352d98605a)


## 4.Images of any 5 best images selected from testing datasets 2
![A0500](https://github.com/anirudhprdhan/new/assets/61653573/7995efee-11c2-4ed5-b2f7-6f0a8438cc4b)
![A0484](https://github.com/anirudhprdhan/new/assets/61653573/0b5a7443-ca40-4c80-a8b5-1842ed034bce)
![A0427](https://github.com/anirudhprdhan/new/assets/61653573/7afa3dd1-9656-4e7b-a73e-9f72e192dcb7)
![A0375](https://github.com/anirudhprdhan/new/assets/61653573/9fb85228-8e2e-45ec-898e-6802c027f12f)
![A0371](https://github.com/anirudhprdhan/new/assets/61653573/b30308f3-e48f-47b2-9ae8-199fd1f1f12a)


## 5.Images of achieved interpretability plot of any 5 best images selected from testing datasets 1

![A0045](https://github.com/anirudhprdhan/new/assets/61653573/9fa447d6-2062-4a7f-89c0-ad9558114970)
![A0036](https://github.com/anirudhprdhan/new/assets/61653573/4e59c473-922c-44a9-896d-34a5d62cc453)
![A0034](https://github.com/anirudhprdhan/new/assets/61653573/1776f3ce-b4b5-4572-8d6a-ef9f1a74e090)
![A0027](https://github.com/anirudhprdhan/new/assets/61653573/d282127d-1ab8-4697-af5a-88f7fbc63396)
![A0001](https://github.com/anirudhprdhan/new/assets/61653573/847187df-7e3c-48dd-bd6a-7a30014eebe7)


## 5.Images of achieved interpretability plot of any 5 best images selected from testing datasets 2

![A0471](https://github.com/anirudhprdhan/new/assets/61653573/ca635a1b-2844-4202-b399-2de1c545c8ec)
![A0453](https://github.com/anirudhprdhan/new/assets/61653573/bb741703-00e1-4508-ab25-95b05c3d4101)
![A0353](https://github.com/anirudhprdhan/new/assets/61653573/8abb0387-3d2f-4fe9-9776-ff3f37f0c6e5)
![A0286](https://github.com/anirudhprdhan/new/assets/61653573/1b2b9c69-821f-458f-b071-33298013fe00)
![A0134](https://github.com/anirudhprdhan/new/assets/61653573/85db1f12-9edc-430c-b2ad-d6169a05c246)

## About the model
The Classification model uses an Ensemble of 3 models, VGG16, MobileNet and ResNet18. Pytorch pretrained models are used without the weights. 

In order to load the data, data augmentation has been used randomly across the training images. Transforms such as Rotations have been used. 

The model also uses HSV color frame in order to train the data.

The Detection model that has been used is the YOLO V8 and bounding boxes have been thus overlayed on top of the images. 

Confidence has been calculated and has been overlayed on the image along with the bounding boxes.


